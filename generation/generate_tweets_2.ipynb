{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "flags = Namespace(\n",
    "    train_file='oliver.txt',\n",
    "    seq_size=40,\n",
    "    batch_size=16,\n",
    "    embedding_size=64,\n",
    "    lstm_size=64,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['I', 'am'],\n",
    "    predict_top_k=5,\n",
    "    checkpoint_path='checkpoint',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_path = '/home/ben/data/tweets/training_set_tweets.txt'\n",
    "OUTPUT_DIR = '/home/ben/data/tweets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(OUTPUT_DIR + 'train.json')\n",
    "valid_df = pd.read_json(OUTPUT_DIR + 'valid.json')\n",
    "test_df = pd.read_json(OUTPUT_DIR + 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_df.text_no_tags.to_list()\n",
    "hashtags = train_df.hashtags_text.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = ' '.join(sum([],test_df.text_no_tags.to_list() + test_df.hashtags_text.to_list())).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(sum([],text+hashtags)).split() + test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 162193\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter(all_words)\n",
    "sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "n_vocab = len(int_to_vocab)\n",
    "\n",
    "print('Vocabulary size', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(sentence, vocab_to_int=vocab_to_int, seq_len=40):\n",
    "    ints = [vocab_to_int[w] for w in sentence.split()]\n",
    "    return np.concatenate([np.array(ints), np.zeros(tags_len-len(ints))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 40\n",
    "tags_len = 40\n",
    "\n",
    "train_df['int_text'] = train_df.text_no_tags.apply(numericalize)\n",
    "train_df['int_tags'] = train_df.hashtags_text.apply(numericalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['int_text'] = test_df.text_no_tags.apply(numericalize)\n",
    "test_df['int_tags'] = test_df.hashtags_text.apply(numericalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = train_df.int_text.to_list()\n",
    "out_text = train_df.int_tags.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_text[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    for i in range(0, len(in_text), batch_size):\n",
    "        yield in_text[i:i+batch_size], out_text[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = RNNModule(n_vocab, flags.seq_size,\n",
    "                flags.embedding_size, flags.lstm_size)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
    "\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    \n",
    "    in_text = words.text_no_tags.apply(numericalize).to_list()\n",
    "    \n",
    "    hashtags = words.hashtags_text.values\n",
    "    text = words.text_no_tags.values\n",
    "    \n",
    "#     print('-'*20)\n",
    "#     print('gold')\n",
    "#     print(text)\n",
    "#     print(hashtags)\n",
    "#     print('-'*20)\n",
    "    \n",
    "    net.eval()        \n",
    "\n",
    "    state_h, state_c = net.zero_state(5)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    ix = torch.tensor(in_text).long().to(device)\n",
    "    \n",
    "    output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "#     print(output[0])\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    \n",
    "    \n",
    "    for n, c in enumerate(choices[:len(text)]):\n",
    "        try:\n",
    "            print('-'*20)\n",
    "            print('gold')\n",
    "            print(text[n])\n",
    "            print(hashtags[n])\n",
    "            print('prediction:   ')\n",
    "            print([int_to_vocab[w] for w in c])\n",
    "            print('-'*20)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "#     words.append(int_to_vocab[choice])\n",
    "    \n",
    "#     for _ in range(100):\n",
    "#         ix = torch.tensor([[choice]]).to(device)\n",
    "#         output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "#         _, top_ix = torch.topk(output[0], k=top_k)\n",
    "#         choices = top_ix.tolist()\n",
    "#         choice = np.random.choice(choices[0])\n",
    "#         words.append(int_to_vocab[choice])\n",
    "\n",
    "#     print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 Iteration: 100 Loss: 0.8700257539749146\n",
      "Epoch: 0/200 Iteration: 200 Loss: 0.39841514825820923\n",
      "Epoch: 0/200 Iteration: 300 Loss: 0.4980195462703705\n",
      "Epoch: 0/200 Iteration: 400 Loss: 0.32982662320137024\n",
      "Epoch: 0/200 Iteration: 500 Loss: 0.7507055401802063\n",
      "Epoch: 0/200 Iteration: 600 Loss: 0.4355921745300293\n",
      "Epoch: 0/200 Iteration: 700 Loss: 0.4667157530784607\n",
      "Epoch: 0/200 Iteration: 800 Loss: 0.43873634934425354\n",
      "Epoch: 0/200 Iteration: 900 Loss: 0.41016799211502075\n",
      "Epoch: 0/200 Iteration: 1000 Loss: 0.3848070800304413\n",
      "--------------------\n",
      "gold\n",
      "RT @PatriaPet barks to @DogTipper @KimPup @petxpert @rescuegal @DOGliving @bestbullysticks @SwtGeorgiaBrwn @Lovemy3goldens @Sylviasnote\n",
      "#FF\n",
      "prediction:   \n",
      "['#outdoor', '#YouMightBeALiberal', '#uneedyourassbeat', '#producer', '#estespark']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "I cry at Formula 1 qualifying.\n",
      "#iamsinglebecause\n",
      "prediction:   \n",
      "['#EasternStandard', 'the', '#TIGERWOODS', '#football', '#SOT']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "Hey @souljaboytellem TAKE YA CLOTHES OFF  (#SouljaBoyVsTwitter live > http://ustre.am/2UhS)\n",
      "#SouljaBoyVsTwitter\n",
      "prediction:   \n",
      "['#digg', '#stocks', '#Technology', '#1', '#web2.0']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "You've......got..........to be kidding........me!\n",
      "#bills\n",
      "prediction:   \n",
      "['#affiliate#marketing', '#autism', '#trading', '#web2.0', '#TravelocityTTF']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "Whitney Port Visits ‘Live with Regis and Kelly’ http://bit.ly/xiuaJ\n",
      "#celebrity\n",
      "prediction:   \n",
      "['the', '#stocks', '#trading', '#affiliate#marketing', '#digg']\n",
      "--------------------\n",
      "Epoch: 0/200 Iteration: 1100 Loss: 0.34572145342826843\n",
      "Epoch: 0/200 Iteration: 1200 Loss: 0.13007143139839172\n",
      "Epoch: 0/200 Iteration: 1300 Loss: 0.6345716714859009\n",
      "Epoch: 0/200 Iteration: 1400 Loss: 0.909458339214325\n",
      "Epoch: 0/200 Iteration: 1500 Loss: 0.34989601373672485\n",
      "Epoch: 0/200 Iteration: 1600 Loss: 0.4993298053741455\n",
      "Epoch: 0/200 Iteration: 1700 Loss: 0.3673514723777771\n",
      "Epoch: 0/200 Iteration: 1800 Loss: 0.37401655316352844\n",
      "Epoch: 0/200 Iteration: 1900 Loss: 0.45434290170669556\n",
      "Epoch: 0/200 Iteration: 2000 Loss: 0.4025530219078064\n",
      "--------------------\n",
      "gold\n",
      "Miniaturized and 2010 schedules, courtesy of @ChrisDeLuca and the @SunTimes http://tinyurl.com/p7627w\n",
      "#Cubs #WhiteSox\n",
      "prediction:   \n",
      "['the', '#steelers', '#style', '#39;Twilight&#39;', '#twist']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "Kickoff time bitches! Starting the day with / then / in the late afternoon. Beer will be flowing!\n",
      "#Chiefs #Radiers, #Broncos #Browns\n",
      "prediction:   \n",
      "['#Photoshop', 'the', '#39;&#39;', '#LA', '#addicted2']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "just joined a video chat at http://tinychat.com/wildandwetwednesdaystinychatparty Make your own video chat at http://tinychat.com\n",
      "#tinychat\n",
      "prediction:   \n",
      "['the', '#fb', '#39;s', '#FF', '#tcot']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "♥ Black Eye by Uncle Tupelo http://bit.ly/OdlkP amazon: http://bit.ly/mKuao\n",
      "#lastfm:\n",
      "prediction:   \n",
      "['the', '#p2', '#39;s', '#fb', '#tlot']\n",
      "--------------------\n",
      "--------------------\n",
      "gold\n",
      "Hiring a Legal Assistant Immigration (Los Angeles, CA) http://bit.ly/yolMw\n",
      "#jobs #shjobs\n",
      "prediction:   \n",
      "['the', '#rock', '#p2', '#39;s', '#tcot']\n",
      "--------------------\n",
      "Epoch: 0/200 Iteration: 2100 Loss: 0.5408108830451965\n",
      "Epoch: 0/200 Iteration: 2200 Loss: 0.46737489104270935\n",
      "Epoch: 0/200 Iteration: 2300 Loss: 0.5469831824302673\n",
      "Epoch: 0/200 Iteration: 2400 Loss: 0.4999004900455475\n",
      "Epoch: 0/200 Iteration: 2500 Loss: 0.3299057185649872\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 1, 64), got (1, 16, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-23aa9553fe09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b8c6380b146f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prev_state)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 512\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    513\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    514\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 1, 64), got (1, 16, 64)"
     ]
    }
   ],
   "source": [
    "for e in range(50):\n",
    "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
    "    state_h, state_c = net.zero_state(flags.batch_size)\n",
    "\n",
    "    # Transfer data to GPU\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for x, y in batches:\n",
    "        iteration += 1\n",
    "\n",
    "        # Tell it we are in training mode\n",
    "        net.train()\n",
    "\n",
    "        # Reset all gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Transfer data to GPU\n",
    "        x = torch.tensor(x).long().to(device)\n",
    "        y = torch.tensor(y).long().to(device)\n",
    "#         print(x.shape)\n",
    "        logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "        loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        # Perform back-propagation\n",
    "#         loss.backward()\n",
    "\n",
    "        # Update the network's parameters\n",
    "        optimizer.step()\n",
    "        loss.backward()\n",
    "\n",
    "        _ = torch.nn.utils.clip_grad_norm_(\n",
    "            net.parameters(), flags.gradients_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "        if iteration % 100 == 0:\n",
    "            print('Epoch: {}/{}'.format(e, 200),\n",
    "                  'Iteration: {}'.format(iteration),\n",
    "                  'Loss: {}'.format(loss_value))\n",
    "\n",
    "        if iteration % 1000 == 0:\n",
    "            predict(device, net, test_df.sample(n=5), n_vocab,\n",
    "                    vocab_to_int, int_to_vocab, top_k=5)\n",
    "            torch.save(net.state_dict(),\n",
    "                       'model-{}.pth'.format(iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([test_df.sample(n=5).hashtags_text.apply(numericalize).to_list()]).long().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
